{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f342af57",
   "metadata": {},
   "source": [
    "# Legal Contract Clause Classification using Stacked LSTM\n",
    "## CCS 248 – Artificial Neural Networks Final Project\n",
    "---\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "**Automated Classification of Legal Contract Clauses**\n",
    "\n",
    "Lawyers spend hours manually reading and categorizing individual contract clauses (e.g., governing law, termination, confidentiality). This project automates that process using deep learning to classify each clause context into predefined legal categories.\n",
    "\n",
    "## Solution: Stacked Bidirectional LSTM with Attention\n",
    "\n",
    "Using a 2-layer bidirectional LSTM network plus an attention pooling head:\n",
    "- **Bidirectional processing** — reads clauses forward and backward for full context\n",
    "- **Stacked layers + attention** — captures low-level patterns and focuses on salient tokens\n",
    "- **Dropout regularization** — prevents overfitting on legal jargon\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**CUAD v1 master_clauses.csv** (flattened clause snippets)\n",
    "- 1,965 snippets, 40 clause labels originally\n",
    "- Filtered to 7 clause types with at least 5 examples each for stable stratification\n",
    "\n",
    "## Target\n",
    "\n",
    "**Test Accuracy: 50-60%** (course requirement)\n",
    "\n",
    "**Evaluation**: Accuracy, macro F1, per-class precision/recall, confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3447d",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ac66423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.9.1+cpu\n",
      "NumPy Version: 2.1.3\n",
      "Pandas Version: 2.2.3\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Core data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# Text processing\n",
    "import string\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# PyTorch for deep learning (avoid Keras)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Scikit-learn for preprocessing and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Display versions\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fa1ee",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33840dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading XLSX files from: d:\\\\CodingRelated\\\\Codes.Ams\\\\ANNFINAL\\\\CUAD_v1\\\\label_group_xlsx\n",
      "✓ Loaded 8035 snippets from 28 XLSX files\n",
      "Unique clause types: 47\n"
     ]
    }
   ],
   "source": [
    "# Load clause snippets from CUAD XLSX sheets (label_group_xlsx)\n",
    "import glob\n",
    "XLSX_DIR = r\"d:\\\\CodingRelated\\\\Codes.Ams\\\\ANNFINAL\\\\CUAD_v1\\\\label_group_xlsx\"\n",
    "print(f\"Loading XLSX files from: {XLSX_DIR}\")\n",
    "\n",
    "def load_xlsx_snippets(xlsx_dir: str):\n",
    "    rows = []\n",
    "    files = glob.glob(os.path.join(xlsx_dir, \"*.xlsx\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .xlsx files found in {xlsx_dir}\")\n",
    "    for path in files:\n",
    "        df_x = pd.read_excel(path)\n",
    "        if df_x.empty:\n",
    "            continue\n",
    "        clause_cols = [c for c in df_x.columns if c != df_x.columns[0]]\n",
    "        for _, row in df_x.iterrows():\n",
    "            for col in clause_cols:\n",
    "                text = row[col]\n",
    "                if pd.isna(text):\n",
    "                    continue\n",
    "                text = str(text).strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                rows.append({\"context\": text, \"clause_type\": col})\n",
    "    df_out = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "    return df_out, len(files)\n",
    "\n",
    "df, n_files = load_xlsx_snippets(XLSX_DIR)\n",
    "print(f\"✓ Loaded {len(df)} snippets from {n_files} XLSX files\")\n",
    "print(f\"Unique clause types: {df['clause_type'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d0c97e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             context        clause_type\n",
      "0  MA may not assign, sell, lease or otherwise tr...    Anti-assignment\n",
      "1  This Agreement may not be assigned, sold or tr...    Anti-assignment\n",
      "2  For purposes of the preceding sentence, and wi...  Change of Control\n",
      "3  Licensee shall not assign or otherwise transfe...    Anti-assignment\n",
      "4  Licensee shall have the right to assign or sub...    Anti-assignment\n",
      "\n",
      "Top clause counts:\n",
      "clause_type\n",
      "Parties                      505\n",
      "Parties-Answer               499\n",
      "Agreement Date               464\n",
      "Governing Law                435\n",
      "Agreement Date-Answer        424\n",
      "Expiration Date              411\n",
      "Effective Date               384\n",
      "Anti-assignment              372\n",
      "Effective Date-Answer        328\n",
      "Document Name                311\n",
      "Cap on Liability             275\n",
      "License Grant                254\n",
      "Expiration Date-Answer       249\n",
      "Audit Rights                 214\n",
      "Post-termination Services    182\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic dataset overview\n",
    "print(df.head())\n",
    "print(\"\\nTop clause counts:\")\n",
    "print(df['clause_type'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97ba116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total snippets: 8035\n",
      "Unique clause types: 47\n",
      "Average length (words): 74.6\n"
     ]
    }
   ],
   "source": [
    "# Dataset stats\n",
    "print(f\"Total snippets: {len(df)}\")\n",
    "print(f\"Unique clause types: {df['clause_type'].nunique()}\")\n",
    "print(f\"Average length (words): {df['context'].apply(lambda x: len(str(x).split())).mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38b61748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "First 5 Rows of Dataset:\n",
      "================================================================================\n",
      "                                             context        clause_type\n",
      "0  MA may not assign, sell, lease or otherwise tr...    Anti-assignment\n",
      "1  This Agreement may not be assigned, sold or tr...    Anti-assignment\n",
      "2  For purposes of the preceding sentence, and wi...  Change of Control\n",
      "3  Licensee shall not assign or otherwise transfe...    Anti-assignment\n",
      "4  Licensee shall have the right to assign or sub...    Anti-assignment\n",
      "\n",
      "================================================================================\n",
      "Dataset Info:\n",
      "================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8035 entries, 0 to 8034\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   context      8035 non-null   object\n",
      " 1   clause_type  8035 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 125.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 5 Rows of Dataset:\")\n",
    "print(\"=\"*80)\n",
    "print(df.head())\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\"*80)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ad8e5",
   "metadata": {},
   "source": [
    "# 3. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81dd5259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "context        0\n",
      "clause_type    0\n",
      "dtype: int64\n",
      "\n",
      "Total samples: 8035\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nTotal samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8071f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 clause types:\n",
      "clause_type\n",
      "Parties                  505\n",
      "Parties-Answer           499\n",
      "Agreement Date           464\n",
      "Governing Law            435\n",
      "Agreement Date-Answer    424\n",
      "Expiration Date          411\n",
      "Effective Date           384\n",
      "Anti-assignment          372\n",
      "Effective Date-Answer    328\n",
      "Document Name            311\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Top 10 clause types:\")\n",
    "print(df['clause_type'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66c8cd",
   "metadata": {},
   "source": [
    "# 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78ad9e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: THIS AGREEMENT is made on January 1, 2020!!!\n",
      "After: this agreement is made on january ,\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Basic text cleaning\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s\\.,;:\\-]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Test\n",
    "sample = \"THIS AGREEMENT is made on January 1, 2020!!!\"\n",
    "print(\"Before:\", sample)\n",
    "print(\"After:\", clean_text(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6dbd3b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned all documents\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['context'].apply(clean_text)\n",
    "print(\"✓ Cleaned all documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f08f17",
   "metadata": {},
   "source": [
    "# 5. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "302c0d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using 8035 clause contexts (no truncation needed)\n"
     ]
    }
   ],
   "source": [
    "# Use cleaned text directly (clause contexts are already short)\n",
    "df['sampled_text'] = df['cleaned_text']\n",
    "print(f\"✓ Using {len(df)} clause contexts (no truncation needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a4d8a",
   "metadata": {},
   "source": [
    "# 6. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd43de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    \"\"\"Simple tokenizer - built from scratch\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size=10000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word_to_index = {\"<OOV>\": 1}\n",
    "        self.word_counts = Counter()\n",
    "        \n",
    "    def fit_on_texts(self, texts):\n",
    "        for text in texts:\n",
    "            self.word_counts.update(str(text).split())\n",
    "        \n",
    "        most_common = self.word_counts.most_common(self.vocab_size - 2)\n",
    "        for idx, (word, _) in enumerate(most_common, start=2):\n",
    "            self.word_to_index[word] = idx\n",
    "        \n",
    "        print(f\"Vocabulary size: {len(self.word_to_index)}\")\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            seq = [self.word_to_index.get(word, 1) for word in str(text).split()]\n",
    "            sequences.append(seq)\n",
    "        return sequences\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return len(self.word_to_index)\n",
    "\n",
    "# Tokenizer will be built after filtering to top clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970fb9f",
   "metadata": {},
   "source": [
    "# 7. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6128b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, maxlen, padding='post', value=0):\n",
    "    \"\"\"Pad sequences to the same length\"\"\"\n",
    "    padded = np.zeros((len(sequences), maxlen), dtype=np.int32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if len(seq) > maxlen:\n",
    "            if padding == 'post':\n",
    "                padded[i] = seq[:maxlen]\n",
    "            else:\n",
    "                padded[i] = seq[-maxlen:]\n",
    "        else:\n",
    "            if padding == 'post':\n",
    "                padded[i, :len(seq)] = seq\n",
    "            else:\n",
    "                padded[i, -len(seq):] = seq\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a63819b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6175 samples before augmentation\n",
      "Top clause types (min 5 per class):\n",
      "  1. Parties... (505 samples)\n",
      "  2. Parties-Answer... (499 samples)\n",
      "  3. Agreement Date... (464 samples)\n",
      "  4. Governing Law... (435 samples)\n",
      "  5. Agreement Date-Answer... (424 samples)\n",
      "  6. Expiration Date... (411 samples)\n",
      "  7. Effective Date... (384 samples)\n",
      "  8. Anti-assignment... (372 samples)\n",
      "  9. Effective Date-Answer... (328 samples)\n",
      "  10. Document Name... (311 samples)\n",
      "  11. Cap on Liability... (275 samples)\n",
      "  12. License Grant... (254 samples)\n",
      "  13. Expiration Date-Answer... (249 samples)\n",
      "  14. Audit Rights... (214 samples)\n",
      "  15. Post-termination Services... (182 samples)\n",
      "  16. Termination for Convenience... (181 samples)\n",
      "  17. Exclusivity... (180 samples)\n",
      "  18. Renewal Term... (175 samples)\n",
      "  19. Revenue-Profit Sharing... (166 samples)\n",
      "  20. Insurance... (166 samples)\n",
      "No augmentation applied (all classes already above target or wordnet unavailable)\n",
      "Total samples after augmentation: 6175\n",
      "Vocabulary size: 9999\n",
      "Sequence length percentile(85th): 99\n",
      "Max sequence length used: 99 (capped at 160)\n",
      "Padded shape (filtered): (6175, 99)\n"
     ]
    }
   ],
   "source": [
    "# Select clause types with enough support to stratify\n",
    "TOP_N = 20\n",
    "MIN_COUNT = 5\n",
    "clause_counts = df['clause_type'].value_counts()\n",
    "filtered_counts = clause_counts[clause_counts >= MIN_COUNT]\n",
    "top_clauses = filtered_counts.head(TOP_N).index.tolist()\n",
    "df_filtered = df[df['clause_type'].isin(top_clauses)].copy()\n",
    "\n",
    "print(f\"Using {len(df_filtered)} samples before augmentation\")\n",
    "print(f\"Top clause types (min {MIN_COUNT} per class):\")\n",
    "for i, (clause, count) in enumerate(filtered_counts.head(TOP_N).items(), 1):\n",
    "    print(f\"  {i}. {clause[:80]}... ({count} samples)\")\n",
    "\n",
    "ENABLE_AUGMENTATION = True\n",
    "TARGET_MIN_PER_CLASS = 30  # desired minimum rows per class after augmentation\n",
    "REPLACE_PROB = 0.25        # probability of replacing a token with a synonym\n",
    "MAX_AUG_PER_CLASS = 80     # cap to avoid explosion per class\n",
    "\n",
    "if ENABLE_AUGMENTATION:\n",
    "    import random\n",
    "    try:\n",
    "        import nltk\n",
    "        from nltk.corpus import wordnet as wn\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "        nltk.download('omw-1.4', quiet=True)\n",
    "    except Exception as e:\n",
    "        wn = None\n",
    "        print(f\"NLTK/wordnet not available, skipping synonym augmentation: {e}\")\n",
    "\n",
    "    def get_synonyms(word):\n",
    "        if wn is None:\n",
    "            return []\n",
    "        syns = set()\n",
    "        for syn in wn.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                candidate = lemma.name().replace('_', ' ').lower()\n",
    "                if candidate.isalpha() and candidate != word.lower():\n",
    "                    syns.add(candidate)\n",
    "        return list(syns)\n",
    "\n",
    "    def synonym_replace(text, replace_prob=0.2):\n",
    "        tokens = str(text).split()\n",
    "        new_tokens = []\n",
    "        for tok in tokens:\n",
    "            if random.random() < replace_prob:\n",
    "                syns = get_synonyms(tok)\n",
    "                if syns:\n",
    "                    new_tokens.append(random.choice(syns))\n",
    "                    continue\n",
    "            new_tokens.append(tok)\n",
    "        return \" \".join(new_tokens)\n",
    "\n",
    "    aug_rows = []\n",
    "    for label, group in df_filtered.groupby('clause_type'):\n",
    "        current_count = len(group)\n",
    "        if current_count >= TARGET_MIN_PER_CLASS:\n",
    "            continue\n",
    "        needed = min(TARGET_MIN_PER_CLASS - current_count, MAX_AUG_PER_CLASS)\n",
    "        pool = group['sampled_text'].tolist()\n",
    "        for i in range(needed):\n",
    "            base_text = pool[i % len(pool)]\n",
    "            aug_text = synonym_replace(base_text, replace_prob=REPLACE_PROB)\n",
    "            aug_rows.append({\n",
    "                'context': aug_text,\n",
    "                'clause_type': label,\n",
    "                'cleaned_text': aug_text,\n",
    "                'sampled_text': aug_text,\n",
    "            })\n",
    "\n",
    "    if aug_rows:\n",
    "        df_aug = pd.DataFrame(aug_rows)\n",
    "        df_filtered = pd.concat([df_filtered, df_aug], ignore_index=True)\n",
    "        print(f\"Applied augmentation: +{len(aug_rows)} synthetic rows\")\n",
    "    else:\n",
    "        print(\"No augmentation applied (all classes already above target or wordnet unavailable)\")\n",
    "\n",
    "print(f\"Total samples after augmentation: {len(df_filtered)}\")\n",
    "\n",
    "# Build tokenizer on filtered (and possibly augmented) data with smaller vocab to limit noise\n",
    "tokenizer = CustomTokenizer(vocab_size=10000)\n",
    "tokenizer.fit_on_texts(df_filtered['sampled_text'])\n",
    "\n",
    "# Tokenize filtered data\n",
    "sequences_filtered = tokenizer.texts_to_sequences(df_filtered['sampled_text'])\n",
    "\n",
    "# Length stats and padding length\n",
    "sequence_lengths = [len(seq) for seq in sequences_filtered]\n",
    "percentile_len = int(np.percentile(sequence_lengths, 85))\n",
    "MAX_LENGTH = min(percentile_len, 160)\n",
    "print(f\"Sequence length percentile(85th): {percentile_len}\")\n",
    "print(f\"Max sequence length used: {MAX_LENGTH} (capped at 160)\")\n",
    "\n",
    "# Pad filtered sequences\n",
    "X_filtered = pad_sequences(sequences_filtered, maxlen=MAX_LENGTH, padding='post')\n",
    "print(f\"Padded shape (filtered): {X_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ce57e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV tokens: 1746 / 349594 (0.50%)\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: OOV rate on filtered sequences\n",
    "# OOV token id is 1 in the tokenizer\n",
    "all_tokens = sum(len(seq) for seq in sequences_filtered)\n",
    "oov_tokens = sum(sum(1 for t in seq if t == 1) for seq in sequences_filtered)\n",
    "oov_pct = 100 * oov_tokens / max(1, all_tokens)\n",
    "print(f\"OOV tokens: {oov_tokens} / {all_tokens} ({oov_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93d1f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (6175,)\n",
      "Classes: ['Agreement Date' 'Agreement Date-Answer' 'Anti-assignment' 'Audit Rights'\n",
      " 'Cap on Liability' 'Document Name' 'Effective Date'\n",
      " 'Effective Date-Answer' 'Exclusivity' 'Expiration Date'\n",
      " 'Expiration Date-Answer' 'Governing Law' 'Insurance' 'License Grant'\n",
      " 'Parties' 'Parties-Answer' 'Post-termination Services' 'Renewal Term'\n",
      " 'Revenue-Profit Sharing' 'Termination for Convenience']\n"
     ]
    }
   ],
   "source": [
    "# Encode labels after filtering\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_filtered['clause_type'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Labels shape: {y_encoded.shape}\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e36a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clause types loaded: 47\n",
      "Clause types kept after filtering: 20\n",
      "Kept clause types: ['Parties', 'Parties-Answer', 'Agreement Date', 'Governing Law', 'Agreement Date-Answer', 'Expiration Date', 'Effective Date', 'Anti-assignment', 'Effective Date-Answer', 'Document Name', 'Cap on Liability', 'License Grant', 'Expiration Date-Answer', 'Audit Rights', 'Post-termination Services', 'Termination for Convenience', 'Exclusivity', 'Renewal Term', 'Revenue-Profit Sharing', 'Insurance']\n"
     ]
    }
   ],
   "source": [
    "# Clause counts summary (safe to run after data/filter cells)\n",
    "if 'df' not in globals() or 'top_clauses' not in globals():\n",
    "    print(\"Please run the data load and filtering cells first.\")\n",
    "else:\n",
    "    print(f\"Total clause types loaded: {df['clause_type'].nunique()}\")\n",
    "    print(f\"Clause types kept after filtering: {len(top_clauses)}\")\n",
    "    print(\"Kept clause types:\", top_clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f69fdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TF-IDF matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heral\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic accuracy (test): 0.7890\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6150    0.8849    0.7257       139\n",
      "           1     0.3884    1.0000    0.5595       127\n",
      "           2     0.9813    0.9375    0.9589       112\n",
      "           3     0.9538    0.9688    0.9612        64\n",
      "           4     0.9630    0.9398    0.9512        83\n",
      "           5     1.0000    0.9140    0.9551        93\n",
      "           6     0.5405    0.1739    0.2632       115\n",
      "           7     0.0000    0.0000    0.0000        98\n",
      "           8     0.8810    0.6852    0.7708        54\n",
      "           9     0.7315    0.8862    0.8015       123\n",
      "          10     1.0000    0.0133    0.0263        75\n",
      "          11     1.0000    0.9847    0.9923       131\n",
      "          12     1.0000    0.9600    0.9796        50\n",
      "          13     0.7978    0.9342    0.8606        76\n",
      "          14     1.0000    0.9934    0.9967       152\n",
      "          15     0.9660    0.9467    0.9562       150\n",
      "          16     0.8723    0.7455    0.8039        55\n",
      "          17     0.8889    0.7692    0.8247        52\n",
      "          18     0.9412    0.9600    0.9505        50\n",
      "          19     0.8654    0.8333    0.8491        54\n",
      "\n",
      "    accuracy                         0.7890      1853\n",
      "   macro avg     0.8193    0.7765    0.7593      1853\n",
      "weighted avg     0.7987    0.7890    0.7560      1853\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heral\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\heral\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\heral\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF + Logistic Regression baseline (quick sanity check)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "texts = df_filtered['sampled_text'].astype(str).tolist()\n",
    "labels = y_encoded\n",
    "\n",
    "print('Building TF-IDF matrix...')\n",
    "vect = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "X_tfidf = vect.fit_transform(texts)\n",
    "\n",
    "# Split and train a simple linear classifier\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_tfidf, labels, test_size=0.30, random_state=42, stratify=labels)\n",
    "clf = LogisticRegression(max_iter=2000, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(X_tr, y_tr)\n",
    "acc = clf.score(X_te, y_te)\n",
    "print(f\"TF-IDF Logistic accuracy (test): {acc:.4f}\")\n",
    "\n",
    "# Print detailed per-class report\n",
    "y_pred = clf.predict(X_te)\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_te, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da76fde",
   "metadata": {},
   "source": [
    "# 8. Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c01355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4322, 99)\n",
      "Val: (926, 99)\n",
      "Test: (927, 99)\n",
      "Class counts: [325 297 260 150 192 218 269 230 126 288 174 304 116 178 353 349 127 123\n",
      " 116 127]\n",
      "Class weights (normalized): [0.57139558 0.62526453 0.71424448 1.23802376 0.96720607 0.85185121\n",
      " 0.69034783 0.8074068  1.47383781 0.64480405 1.06726187 0.61086699\n",
      " 1.60089279 1.04327845 0.52607242 0.53210191 1.46223279 1.50978507\n",
      " 1.60089279 1.46223279]\n"
     ]
    }
   ],
   "source": [
    "# Split data: 70% train, 15% val, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_filtered, y_encoded, test_size=0.30, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Val: {X_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n",
    "\n",
    "# Class weights to handle imbalance (toggle with USE_CLASS_WEIGHTS)\n",
    "class_counts = np.bincount(y_train, minlength=num_classes)\n",
    "class_weights = 1.0 / (class_counts + 1e-6)\n",
    "class_weights = class_weights * (num_classes / class_weights.sum())\n",
    "print(\"Class counts:\", class_counts)\n",
    "print(\"Class weights (normalized):\", class_weights)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "USE_CLASS_WEIGHTS = True\n",
    "USE_SAMPLER = True\n",
    "\n",
    "class ClauseDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = ClauseDataset(X_train, y_train)\n",
    "val_dataset = ClauseDataset(X_val, y_val)\n",
    "test_dataset = ClauseDataset(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48211ecb",
   "metadata": {},
   "source": [
    "# 9. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76b5c1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: 9999, Classes: 20, Max length: 99\n"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Bidirectional stacked LSTM with attention for clause classification\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim=200, lstm_1=128, lstm_2=96, dropout=0.25, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n",
    "        self.lstm1 = nn.LSTM(embed_dim, lstm_1, batch_first=True, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.lstm2 = nn.LSTM(lstm_1 * 2, lstm_2, batch_first=True, bidirectional=True)\n",
    "        self.attn = nn.Linear(lstm_2 * 2, 1)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(lstm_2 * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        scores = torch.tanh(self.attn(x))\n",
    "        weights = torch.softmax(scores, dim=1)\n",
    "        context = (x * weights).sum(dim=1)\n",
    "        context = self.dropout2(context)\n",
    "        return self.fc(context)\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_to_index)\n",
    "NUM_CLASSES = num_classes\n",
    "print(f\"Vocab: {VOCAB_SIZE}, Classes: {NUM_CLASSES}, Max length: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a147b",
   "metadata": {},
   "source": [
    "# 10. Hyperparameter Tuning Setup\n",
    "\n",
    "Testing different optimizers as required by the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b4756ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will test 5 configurations\n"
     ]
    }
   ],
   "source": [
    "# Configurations to test - tuned for faster convergence with attention\n",
    "configs = [\n",
    "    {'opt': 'Adam',    'lr': 0.0008, 'wd': 1e-4, 'batch': 64, 'epochs': 5},\n",
    "    {'opt': 'Adam',    'lr': 0.0010, 'wd': 1e-4, 'batch': 64, 'epochs': 10},\n",
    "    {'opt': 'Adam',    'lr': 0.0005, 'wd': 1e-4, 'batch': 64, 'epochs': 5},\n",
    "    {'opt': 'RMSprop', 'lr': 0.0008, 'wd': 0.0,  'batch': 64, 'epochs': 10},\n",
    "    {'opt': 'RMSprop', 'lr': 0.0005, 'wd': 0.0,  'batch': 64, 'epochs': 5},\n",
    "]\n",
    "\n",
    "print(f\"Will test {len(configs)} configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61058ec0",
   "metadata": {},
   "source": [
    "# 11. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "751b7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "models_dir = r'd:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5'\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03ba2d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Config 1/5: Adam, LR=0.0008, WD=0.0001\n",
      "============================================================\n",
      "Model created, starting training...\n",
      "Training batches: 68, Val batches: 15\n",
      "Epoch 1/5 - Train loss 2.4523, acc 0.1564 | Val loss 1.9190, acc 0.2127\n",
      "Epoch 2/5 - Train loss 1.3793, acc 0.4472 | Val loss 1.3115, acc 0.4708\n",
      "Epoch 3/5 - Train loss 0.8800, acc 0.6333 | Val loss 0.8761, acc 0.6339\n",
      "Epoch 4/5 - Train loss 0.5792, acc 0.7411 | Val loss 0.6638, acc 0.7322\n",
      "Epoch 5/5 - Train loss 0.4481, acc 0.7760 | Val loss 0.6295, acc 0.7149\n",
      "Val pred distribution: Counter({np.int64(7): 152, np.int64(6): 105, np.int64(15): 81, np.int64(14): 75, np.int64(11): 65, np.int64(9): 58, np.int64(2): 53, np.int64(5): 41, np.int64(4): 40, np.int64(3): 39, np.int64(8): 37, np.int64(16): 32, np.int64(19): 32, np.int64(18): 30, np.int64(13): 29, np.int64(12): 23, np.int64(17): 21, np.int64(0): 13})\n",
      "Test accuracy: 0.7001\n",
      "Saved: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_1.pt and d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_1.h5\n",
      "\n",
      "============================================================\n",
      "Config 2/5: Adam, LR=0.001, WD=0.0001\n",
      "============================================================\n",
      "Model created, starting training...\n",
      "Training batches: 68, Val batches: 15\n",
      "Epoch 1/10 - Train loss 2.3230, acc 0.1953 | Val loss 1.8712, acc 0.1955\n",
      "Epoch 2/10 - Train loss 1.2619, acc 0.4829 | Val loss 1.2513, acc 0.4816\n",
      "Epoch 3/10 - Train loss 0.7986, acc 0.6691 | Val loss 0.7940, acc 0.6717\n",
      "Epoch 4/10 - Train loss 0.5064, acc 0.7645 | Val loss 0.6308, acc 0.7246\n",
      "Epoch 5/10 - Train loss 0.4147, acc 0.7837 | Val loss 0.6159, acc 0.7084\n",
      "Epoch 6/10 - Train loss 0.3443, acc 0.8080 | Val loss 0.6222, acc 0.7473\n",
      "Epoch 7/10 - Train loss 0.3181, acc 0.8242 | Val loss 0.6298, acc 0.7430\n",
      "Epoch 8/10 - Train loss 0.2937, acc 0.8336 | Val loss 0.5579, acc 0.7495\n",
      "Epoch 9/10 - Train loss 0.2887, acc 0.8207 | Val loss 0.6027, acc 0.7289\n",
      "Epoch 10/10 - Train loss 0.2553, acc 0.8360 | Val loss 0.5877, acc 0.7624\n",
      "Val pred distribution: Counter({np.int64(10): 152, np.int64(0): 104, np.int64(14): 77, np.int64(15): 72, np.int64(11): 64, np.int64(9): 54, np.int64(2): 52, np.int64(13): 45, np.int64(5): 45, np.int64(4): 42, np.int64(3): 37, np.int64(19): 34, np.int64(6): 29, np.int64(12): 28, np.int64(16): 26, np.int64(17): 23, np.int64(8): 21, np.int64(18): 21})\n",
      "Test accuracy: 0.7238\n",
      "Saved: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_2.pt and d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_2.h5\n",
      "\n",
      "============================================================\n",
      "Config 3/5: Adam, LR=0.0005, WD=0.0001\n",
      "============================================================\n",
      "Model created, starting training...\n",
      "Training batches: 68, Val batches: 15\n",
      "Epoch 1/5 - Train loss 2.6065, acc 0.1192 | Val loss 2.2352, acc 0.1577\n",
      "Epoch 2/5 - Train loss 1.7253, acc 0.3216 | Val loss 1.6757, acc 0.3045\n",
      "Epoch 3/5 - Train loss 1.1947, acc 0.5192 | Val loss 1.1935, acc 0.4946\n",
      "Epoch 4/5 - Train loss 0.8480, acc 0.6386 | Val loss 0.9661, acc 0.5907\n",
      "Epoch 5/5 - Train loss 0.6723, acc 0.7136 | Val loss 0.7870, acc 0.6717\n",
      "Val pred distribution: Counter({np.int64(10): 154, np.int64(14): 76, np.int64(9): 67, np.int64(0): 64, np.int64(15): 63, np.int64(11): 61, np.int64(6): 60, np.int64(8): 54, np.int64(4): 48, np.int64(2): 44, np.int64(5): 42, np.int64(18): 42, np.int64(16): 32, np.int64(19): 31, np.int64(17): 30, np.int64(12): 26, np.int64(3): 23, np.int64(13): 9})\n",
      "Test accuracy: 0.6526\n",
      "Saved: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_3.pt and d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_3.h5\n",
      "\n",
      "============================================================\n",
      "Config 4/5: RMSprop, LR=0.0008, WD=0.0\n",
      "============================================================\n",
      "Model created, starting training...\n",
      "Training batches: 68, Val batches: 15\n",
      "Epoch 1/10 - Train loss 1.4893, acc 0.4398 | Val loss 0.9305, acc 0.6166\n",
      "Epoch 2/10 - Train loss 0.5355, acc 0.7608 | Val loss 0.6435, acc 0.7117\n",
      "Epoch 3/10 - Train loss 0.3873, acc 0.7994 | Val loss 0.5533, acc 0.7538\n",
      "Epoch 4/10 - Train loss 0.3163, acc 0.8211 | Val loss 0.5999, acc 0.6901\n",
      "Epoch 5/10 - Train loss 0.3066, acc 0.8209 | Val loss 0.5418, acc 0.7657\n",
      "Epoch 6/10 - Train loss 0.2766, acc 0.8348 | Val loss 0.5842, acc 0.7484\n",
      "Epoch 7/10 - Train loss 0.2592, acc 0.8373 | Val loss 0.5812, acc 0.7559\n",
      "Epoch 8/10 - Train loss 0.2532, acc 0.8387 | Val loss 0.5911, acc 0.7387\n",
      "Epoch 9/10 - Train loss 0.2356, acc 0.8380 | Val loss 0.6337, acc 0.7538\n",
      "Epoch 10/10 - Train loss 0.2222, acc 0.8397 | Val loss 0.5508, acc 0.7549\n",
      "Val pred distribution: Counter({np.int64(10): 152, np.int64(0): 82, np.int64(15): 74, np.int64(14): 74, np.int64(11): 63, np.int64(9): 61, np.int64(2): 53, np.int64(5): 46, np.int64(4): 44, np.int64(6): 41, np.int64(8): 38, np.int64(13): 35, np.int64(3): 34, np.int64(19): 32, np.int64(17): 25, np.int64(12): 25, np.int64(16): 24, np.int64(18): 23})\n",
      "Test accuracy: 0.7433\n",
      "Saved: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_4.pt and d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_4.h5\n",
      "\n",
      "============================================================\n",
      "Config 5/5: RMSprop, LR=0.0005, WD=0.0\n",
      "============================================================\n",
      "Model created, starting training...\n",
      "Training batches: 68, Val batches: 15\n",
      "Epoch 1/5 - Train loss 1.8133, acc 0.3491 | Val loss 1.2653, acc 0.4935\n",
      "Epoch 2/5 - Train loss 0.8373, acc 0.6752 | Val loss 0.7657, acc 0.6717\n",
      "Epoch 3/5 - Train loss 0.5267, acc 0.7647 | Val loss 0.6581, acc 0.7279\n",
      "Epoch 4/5 - Train loss 0.4257, acc 0.7878 | Val loss 0.6240, acc 0.6987\n",
      "Epoch 5/5 - Train loss 0.3533, acc 0.8012 | Val loss 0.6233, acc 0.7343\n",
      "Val pred distribution: Counter({np.int64(10): 134, np.int64(0): 101, np.int64(14): 76, np.int64(15): 71, np.int64(11): 61, np.int64(9): 56, np.int64(2): 56, np.int64(8): 52, np.int64(5): 48, np.int64(4): 42, np.int64(3): 31, np.int64(18): 31, np.int64(19): 31, np.int64(17): 28, np.int64(12): 25, np.int64(6): 21, np.int64(16): 21, np.int64(13): 21, np.int64(7): 20})\n",
      "Test accuracy: 0.7184\n",
      "Saved: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_5.pt and d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5\\model_5.h5\n",
      "\n",
      "✓ Training complete!\n"
     ]
    }
   ],
   "source": [
    "def run_epoch(model, loader, criterion, optimizer=None):\n",
    "    model.train() if optimizer else model.eval()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        if optimizer:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        total_correct += (preds == y_batch).sum().item()\n",
    "        total_samples += X_batch.size(0)\n",
    "        \n",
    "        # Progress indicator every 50 batches\n",
    "        if optimizer and batch_idx % 50 == 0:\n",
    "            print(f\"  Batch {batch_idx}/{len(loader)}\", end='\\r')\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def save_model_as_h5(model, filepath):\n",
    "    \"\"\"Save PyTorch model weights to HDF5 format\"\"\"\n",
    "    import h5py\n",
    "    state_dict = model.state_dict()\n",
    "    with h5py.File(filepath, 'w') as f:\n",
    "        for key, value in state_dict.items():\n",
    "            f.create_dataset(key, data=value.cpu().numpy())\n",
    "\n",
    "results = []\n",
    "models_dir = r'd:\\CodingRelated\\Codes.Ams\\ANNFINAL\\trained_models_run5'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "for i, cfg in enumerate(configs, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Config {i}/{len(configs)}: {cfg['opt']}, LR={cfg['lr']}, WD={cfg['wd']}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    model = LSTMClassifier(VOCAB_SIZE, embed_dim=200, num_classes=NUM_CLASSES).to(device)\n",
    "    print(f\"Model created, starting training...\")\n",
    "    \n",
    "    if cfg['opt'] == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg['lr'], weight_decay=cfg.get('wd', 0.0))\n",
    "    elif cfg['opt'] == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=cfg['lr'], weight_decay=cfg.get('wd', 0.0))\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=cfg['lr'], momentum=0.9, weight_decay=cfg.get('wd', 0.0))\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor if USE_CLASS_WEIGHTS else None)\n",
    "    \n",
    "    if USE_SAMPLER:\n",
    "        sample_weights = class_weights_tensor.cpu().numpy()[y_train]\n",
    "        train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=cfg['batch'], sampler=train_sampler)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_dataset, batch_size=cfg['batch'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg['batch'], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=cfg['batch'], shuffle=False)\n",
    "    \n",
    "    print(f\"Training batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 6\n",
    "    \n",
    "    for epoch in range(cfg['epochs']):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer=None)\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{cfg['epochs']} - Train loss {train_loss:.4f}, acc {train_acc:.4f} | Val loss {val_loss:.4f}, acc {val_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Quick val prediction distribution\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_val_preds = []\n",
    "        for Xb, _ in val_loader:\n",
    "            Xb = Xb.to(device)\n",
    "            preds = model(Xb).argmax(dim=1).cpu().numpy()\n",
    "            all_val_preds.extend(preds)\n",
    "    from collections import Counter\n",
    "    pred_dist = Counter(all_val_preds)\n",
    "    print(f\"Val pred distribution: {pred_dist}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = run_epoch(model, test_loader, criterion, optimizer=None)\n",
    "    results.append({\n",
    "        'config': i,\n",
    "        'optimizer': cfg['opt'],\n",
    "        'lr': cfg['lr'],\n",
    "        'wd': cfg.get('wd', 0.0),\n",
    "        'batch_size': cfg['batch'],\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc\n",
    "    })\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Save model in both PyTorch (.pt) and HDF5 (.h5) formats\n",
    "    pt_path = os.path.join(models_dir, f'model_{i}.pt')\n",
    "    h5_path = os.path.join(models_dir, f'model_{i}.h5')\n",
    "    torch.save(model.state_dict(), pt_path)\n",
    "    save_model_as_h5(model, h5_path)\n",
    "    print(f\"Saved: {pt_path} and {h5_path}\")\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0054f0",
   "metadata": {},
   "source": [
    "# 12. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f42d3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Results:\n",
      "   config optimizer      lr      wd  batch_size  train_acc   val_acc  test_acc\n",
      "0       1      Adam  0.0008  0.0001          64   0.776030  0.714903  0.700108\n",
      "1       2      Adam  0.0010  0.0001          64   0.835956  0.762419  0.723840\n",
      "2       3      Adam  0.0005  0.0001          64   0.713559  0.671706  0.652643\n",
      "3       4   RMSprop  0.0008  0.0000          64   0.839658  0.754860  0.743258\n",
      "4       5   RMSprop  0.0005  0.0000          64   0.801249  0.734341  0.718447\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(r'd:\\CodingRelated\\Codes.Ams\\ANNFINAL\\experiment_results_run2.csv', index=False)\n",
    "\n",
    "print(\"All Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c3d41f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BEST MODEL\n",
      "============================================================\n",
      "Optimizer: RMSprop\n",
      "Learning Rate: 0.0008\n",
      "Test Accuracy: 74.33%\n",
      "\n",
      "✓ Meets 50% requirement!\n"
     ]
    }
   ],
   "source": [
    "# Best model\n",
    "best_idx = results_df['test_acc'].idxmax()\n",
    "best = results_df.iloc[best_idx]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BEST MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Optimizer: {best['optimizer']}\")\n",
    "print(f\"Learning Rate: {best['lr']}\")\n",
    "print(f\"Test Accuracy: {best['test_acc']:.2%}\")\n",
    "\n",
    "if best['test_acc'] >= 0.50:\n",
    "    print(\"\\n✓ Meets 50% requirement!\")\n",
    "else:\n",
    "    print(\"\\n✗ Below 50%\")\n",
    "\n",
    "best_model_path = os.path.join(models_dir, f\"model_{best_idx + 1}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b2ff481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts directory: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\artifacts_run5\n"
     ]
    }
   ],
   "source": [
    "# Artifact paths for this run\n",
    "ARTIFACTS_DIR = r'd:\\CodingRelated\\Codes.Ams\\ANNFINAL\\artifacts_run5'\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# Persist tokenizer and label encoder classes\n",
    "with open(os.path.join(ARTIFACTS_DIR, 'tokenizer_word_index.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(tokenizer.word_to_index, f)\n",
    "np.save(os.path.join(ARTIFACTS_DIR, 'label_classes.npy'), label_encoder.classes_)\n",
    "\n",
    "print(f\"Artifacts directory: {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb130d8",
   "metadata": {},
   "source": [
    "# 13. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "022d710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from: model_4.pt\n"
     ]
    }
   ],
   "source": [
    "# Load best model (match training embed_dim)\n",
    "best_model = LSTMClassifier(VOCAB_SIZE, embed_dim=200, num_classes=NUM_CLASSES).to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "best_model.eval()\n",
    "\n",
    "# Get predictions\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.long).to(device)\n",
    "with torch.no_grad():\n",
    "    y_pred = best_model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = y_test\n",
    "\n",
    "print(f\"Loaded best model from: model_{best_idx + 1}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fca778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[55  0  0  0  0  1 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 64  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 52  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  2]\n",
      " [ 0  0  0 31  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  0 34  0  0  0  2  0  0  0  0  0  0  0  3  0  1  0]\n",
      " [ 1  0  0  0  0 43  1  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [34  0  0  0  0  0 20  0  0  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 49  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0 22  0  0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  5  0  0 44  0  0  0  1  0  0  1  8  0  3]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 66  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  0  1  0  0  0  9  0  0  0  0 27  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 76  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 75  0  0  0  0]\n",
      " [ 0  0  1  3  0  0  0  0  2  2  0  0  0  0  0  0 18  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1 23  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  1  0 22  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  0  0  2  0  0  1  1  0 21]]\n",
      "\n",
      "Saved confusion matrix to: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\artifacts_run5\\confusion_matrix.csv\n",
      "\n",
      "Accuracy per class:\n",
      "Agreement Date: 78.57%\n",
      "Agreement Date-Answer: 0.00%\n",
      "Anti-assignment: 92.86%\n",
      "Audit Rights: 96.88%\n",
      "Cap on Liability: 82.93%\n",
      "Document Name: 93.48%\n",
      "Effective Date: 34.48%\n",
      "Effective Date-Answer: 0.00%\n",
      "Exclusivity: 81.48%\n",
      "Expiration Date: 70.97%\n",
      "Expiration Date-Answer: 100.00%\n",
      "Governing Law: 100.00%\n",
      "Insurance: 92.00%\n",
      "License Grant: 71.05%\n",
      "Parties: 100.00%\n",
      "Parties-Answer: 100.00%\n",
      "Post-termination Services: 66.67%\n",
      "Renewal Term: 88.46%\n",
      "Revenue-Profit Sharing: 88.00%\n",
      "Termination for Convenience: 77.78%\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix - save and print\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "\n",
    "cm_path = os.path.join(ARTIFACTS_DIR, 'confusion_matrix.csv')\n",
    "cm_df.to_csv(cm_path)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nSaved confusion matrix to: {cm_path}\")\n",
    "print(f\"\\nAccuracy per class:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
    "    print(f\"{class_name}: {class_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5308458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score     support\n",
      "Agreement Date                0.611111  0.785714  0.687500   70.000000\n",
      "Agreement Date-Answer         0.000000  0.000000  0.000000   64.000000\n",
      "Anti-assignment               0.945455  0.928571  0.936937   56.000000\n",
      "Audit Rights                  0.911765  0.968750  0.939394   32.000000\n",
      "Cap on Liability              0.971429  0.829268  0.894737   41.000000\n",
      "Document Name                 0.977273  0.934783  0.955556   46.000000\n",
      "Effective Date                0.500000  0.344828  0.408163   58.000000\n",
      "Effective Date-Answer         0.000000  0.000000  0.000000   49.000000\n",
      "Exclusivity                   0.578947  0.814815  0.676923   27.000000\n",
      "Expiration Date               0.846154  0.709677  0.771930   62.000000\n",
      "Expiration Date-Answer        0.246667  1.000000  0.395722   37.000000\n",
      "Governing Law                 1.000000  1.000000  1.000000   66.000000\n",
      "Insurance                     1.000000  0.920000  0.958333   25.000000\n",
      "License Grant                 0.794118  0.710526  0.750000   38.000000\n",
      "Parties                       1.000000  1.000000  1.000000   76.000000\n",
      "Parties-Answer                0.986842  1.000000  0.993377   75.000000\n",
      "Post-termination Services     0.620690  0.666667  0.642857   27.000000\n",
      "Renewal Term                  0.676471  0.884615  0.766667   26.000000\n",
      "Revenue-Profit Sharing        0.916667  0.880000  0.897959   25.000000\n",
      "Termination for Convenience   0.777778  0.777778  0.777778   27.000000\n",
      "accuracy                      0.743258  0.743258  0.743258    0.743258\n",
      "macro avg                     0.718068  0.757800  0.722692  927.000000\n",
      "weighted avg                  0.717752  0.743258  0.717850  927.000000\n",
      "\n",
      "Saved classification report to: d:\\CodingRelated\\Codes.Ams\\ANNFINAL\\artifacts_run5\\classification_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Classification report - save to artifacts\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(\n",
    "    y_true_classes,\n",
    "    y_pred_classes,\n",
    "    target_names=label_encoder.classes_,\n",
    "    output_dict=True,\n",
    "    zero_division=0,\n",
    ")\n",
    "report_df = pd.DataFrame(report).T\n",
    "print(report_df)\n",
    "\n",
    "report_path = os.path.join(ARTIFACTS_DIR, 'classification_report.csv')\n",
    "report_df.to_csv(report_path)\n",
    "print(f\"\\nSaved classification report to: {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
